import os
import sys
import traceback
from dotenv import load_dotenv
import pandas as pd
import torch

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.tools import tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.agents import create_agent

# ==================== TEMEL BÄ°LGÄ°LER ====================
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LLM = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.7, google_api_key=GOOGLE_API_KEY)


# ==================== 1. VERÄ° YÃœKLEME & PARÃ‡ALAMA ====================

def load_and_split_documents():
    try:
        # df = pd.read_csv("datav2.csv")
        df = pd.read_csv("datav2.csv", nrows=10)
        print("10 satÄ±rÄ± baÅŸarÄ±yla yÃ¼klendi.")
        print("=== YÃœKLENEN SATIRLAR (Ã–N Ä°ZLEME) ===")
        print(df.to_string(index=False))  # tÃ¼m sÃ¼tunlarÄ± dÃ¼zgÃ¼n ÅŸekilde gÃ¶ster
        print("=====================================\n")
    except FileNotFoundError:
        print("Hata: 'datav2.csv' dosyasÄ± bulunamadÄ±.")
        return []
    except Exception as e:
        print(f"CSV yÃ¼kleme hatasÄ±: {e}")
        traceback.print_exc()
        return []

    docs = []
    for _, row in df.iterrows():
        title = row.get("Title", "Bilinmiyor")
        content = (
            f"Yemek AdÄ±: {title}\n\n"
            f"Malzemeler: {row.get('Materials', 'Yok')}\n\n"
            f"Tarif: {row.get('How-to-do', 'Yok')}"
        )
        docs.append(Document(page_content=content, metadata={"title": title}))

    print(f"{len(docs)} adet tarif dÃ¶kÃ¼manÄ± oluÅŸturuldu.")

    # Metni parÃ§alara ayÄ±r
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    try:
        splits = text_splitter.split_documents(docs)
    except Exception as e:
        print("Text splitter sÄ±rasÄ±nda hata:", e)
        traceback.print_exc()
        return []

    print(f"Toplam {len(splits)} adet metin parÃ§asÄ±na bÃ¶lÃ¼ndÃ¼.")
    return splits


# ==================== 2. VEKTÃ–R DEPOSU OLUÅTURMA ====================

def create_vector_store(splits, persist: bool = False):
    if not splits:
        print("UyarÄ±: 'splits' listesi boÅŸ. VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±.")
        return None

    try:
        print(f"{len(splits)} dÃ¶kÃ¼manla vektÃ¶r veritabanÄ± oluÅŸturuluyor...")
        embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large", model_kwargs={"device": "cpu"})
        try:
            vector_store = Chroma.from_documents(documents=splits, embedding=embeddings,
                                                 persist_directory="./chroma_store" if persist else None)
        except TypeError:
            vector_store = Chroma.from_documents(documents=splits, embedding=embeddings)
        print("Chroma VektÃ¶r Deposu baÅŸarÄ±yla oluÅŸturuldu!")
        return vector_store
    except Exception as e:
        print(f"VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±: {e}")
        traceback.print_exc()
        return None


# ==================== 3. RAG ZÄ°NCÄ°RÄ° (retrieve tool + agent) ====================

def make_retrieve_context_tool(vector_store):
    from langchain_core.tools import tool
    import traceback

    @tool(description="KullanÄ±cÄ±nÄ±n sorusuna uygun tarifleri ve malzemeleri getirir.")
    def retrieve_context(question: str) -> str:
        if vector_store is None:
            return "VektÃ¶r veritabanÄ± bulunamadÄ±!"
        try:
            docs = vector_store.similarity_search(question, k=5)
        except Exception as e:
            print("Similarity search hatasÄ±:", e)
            traceback.print_exc()
            return "VeritabanÄ± aramasÄ± sÄ±rasÄ±nda hata oluÅŸtu."

        if not docs:
            return "Veri bulunamadÄ±."

        composed = ""
        for doc in docs:
            title = doc.metadata.get("title", "Bilinmiyor")
            composed += (
                f"\nğŸ½ï¸ Yemek AdÄ±: {title}\n"
                f"ğŸ§‚ Malzemeler: {doc.page_content.split('Malzemeler: ')[-1].split('Tarif:')[0].strip()}\n"
                f"ğŸ‘¨â€ğŸ³ Tarif: {doc.page_content.split('Tarif: ')[-1].strip()}\n"
                "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            )
        return composed

    return retrieve_context


def create_rag_chain(vector_store):
    from rag_chatbot import create_agent, LLM
    import traceback

    system_prompt = (
        "Sen PROFESYONEL BÄ°R ÅEFSÄ°N ve bir yemek tarifleri uzmanÄ±sÄ±n. "
        "KullanÄ±cÄ± sorularÄ±nÄ± yanÄ±tlamak iÃ§in aÅŸaÄŸÄ±daki 'baÄŸlam' kÄ±smÄ±nÄ± kullanmalÄ±sÄ±n. "
        "KapsamlÄ±, adÄ±m adÄ±m ve samimi cevaplar ver. "
        "EÄŸer baÄŸlamda soruyla ilgili bilgi yoksa, "
        "\"ÃœzgÃ¼nÃ¼m, veri setimde bu tarife dair bir bilgi bulunmamaktadÄ±r.\" diye cevap ver.\n\n"
        "AyrÄ±ca sadece yemek tarifi deÄŸil, aÅŸaÄŸÄ±daki tÃ¼rden sorulara da yanÄ±t verebilmelisin:\n"
        "DÄ°L KURALLARI:\n"
        "- TÃ¼rkÃ§e ek ve kÃ¶k analizine dikkat et.\n"
        "- Fiillerin Ã§ekimli halleri (Ã¶rneÄŸin 'yapmak', 'yapÄ±yorum', 'yapayÄ±m', 'yapabilir miyim', 'yapÄ±lÄ±r mÄ±') "
        "aynÄ± kÃ¶kten ('yapmak') tÃ¼rediÄŸi iÃ§in hepsi aynÄ± anlam kategorisine ait olarak deÄŸerlendirilmelidir.\n"
        "- Bu kural sadece fiiller iÃ§in deÄŸil, isim-fiil ve sÄ±fat-fiil tÃ¼revleri iÃ§in de geÃ§erlidir.\n"
        "- KullanÄ±cÄ± sorusundaki fiil veya isimleri kÃ¶k hÃ¢line indir ve anlamÄ± bu kÃ¶ke gÃ¶re eÅŸleÅŸtir.\n"
        "- BugÃ¼n hangi yemeÄŸi yapmalÄ±yÄ±m?\n"
        "- 'X' yemeÄŸi nasÄ±l yapÄ±lÄ±r?\n"
        "- 'X' yemeÄŸi iÃ§in hangi malzemeler gereklidir?\n"
        "- 'X' malzemeleri ile hangi yemeÄŸi yapabilirim?\n"
        "- 'X' yemeÄŸinin yanÄ±nda ne iyi gider?\n\n"
        "BAÄLAM:\n{context}"
    )
    retrieve_tool = make_retrieve_context_tool(vector_store)

    try:
        rag_chain = create_agent(tools=[retrieve_tool], model=LLM, system_prompt=system_prompt)
    except Exception as e:
        print("RAG chain oluÅŸturulurken hata:", e)
        traceback.print_exc()
        return None

    return rag_chain


def run_rag_simple(rag_chain, question: str, verbose: bool = False) -> str:
    """RAG zincirinden gelen cevabÄ± yakalayÄ±p dÃ¼zgÃ¼n biÃ§imde dÃ¶ndÃ¼rÃ¼r."""
    full_response = ""
    inputs = {"messages": [{"role": "user", "content": question}]}

    try:
        for event in rag_chain.stream(inputs, stream_mode="updates"):
            print(event)
            text_part = ""
            if isinstance(event, str):
                text_part = event
            elif isinstance(event, dict):
                if "text" in event:
                    text_part = event["text"]
                elif "output_text" in event:
                    text_part = event["output_text"]
                elif "output" in event and isinstance(event["output"], dict):
                    content = event["output"].get("content")
                    if isinstance(content, str):
                        text_part = content
                    elif isinstance(content, list):
                        text_part = "".join(
                            c.get("text", "") for c in content if isinstance(c, dict)
                        )
                elif "model" in event and "messages" in event["model"]:
                    msg = event["model"]["messages"][0]
                    if hasattr(msg, "content") and isinstance(msg.content, list):
                        text_part = "".join(
                            c["text"] for c in msg.content if isinstance(c, dict) and "text" in c
                        )
            if text_part:
                full_response += text_part
                if verbose:
                    print(text_part, end="", flush=True)

        print("\n" + "-" * 60)
        print("Cevap tamamlandÄ±.")
        print("-" * 60)
        return full_response.strip()

    except Exception as e:
        print(f"run_rag_simple hatasÄ±: {e}")
        traceback.print_exc()
        return ""
